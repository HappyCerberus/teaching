\documentclass[10pt]{article}

\begin{document}

\section{Introduction}

Welcome, thank you all for comming here today.
My name is Šimon Tóth.

I work for CESNET, where I work on the Czech National Grid Infrastructure 
and my Ph.D. studies are conducted in cooperation with CESNET and also CERIT.

I'm in my first year of PhD studies, and therefore right now, I have mostly
questions and issues and chalenges and not many solutions to present.  And
since you are quite a diverse audience, specializing in various fields, I
prepared an introductory talk for you.

I apologize to those who are familiar with job and GRID scheduling, because
this talk won't probably give you much new information.

\section{Quiz}

Just to get a quick overview of how many people here are familiar with this
subject, please allow me a short quiz.

Please raise your hand, if you are familiar with scheduling. Thank you.

Please raise your hand, if you are familiar with job scheduling. Thank you.

Just please raise hand, if you know what a grid is. Thank you.

Please raise your hand, if you ever heard about MetaCentrum or Cerit. Thank you.

Please raise your hand, if you ever used a grid. Thank you.

\section{Categories}

Now at least those of you that know what a grid is might have some mental image
of how the grid looks like.  This image here, actually doesn't show a grid.
This is an image of one of the older generation of BlueGene, which is a
supercomputer.

So allow me please to shortly introduce you into the different categories of
supercomputing elements you might encounter.  And let's start with
supercomputers.

Supercomputers are a computing model you would probably look for, when you needed the
maximum possible performace, or when you had a use case for which you already
had some estimate of required procesing prower. Or of course, when you somehow
got access to huge amount of money and didn't know where to spend it.

Supercomputers are very expensive, so you won't be buying a supercomputer for
just two years. Therefore most supercomputers are actually not usable for
generic computing and you will most likely be developing specific software for
your supercomputer, just to use it to the fullest.

Of course initially all computers could be categorized as supercomputers. They
were huge, extremely expensive, were maintained for very long time.

With the advent of personal computers and workstations, we small compact server.
At this point, you could actually build a reasonably powerful computing element
by connecting multiple workstations or server using a fast network. And then by
exploiting paralelization you could run your software reasonably fast, without
expending huge amount of money.

One very specific atribute of clusters is that each cluster is a homogenous
environment. When you buy a cluster, you are buing a set of machines, that are
identical in their configuration. This brings with itself one big issue.
Although clusters are actually much cheaper then supercomputers, you still have
to expend a lot of money.

The issue here is that wile clusters are much less expensive than
supercomputers, supercomputers are so expensive, that you will most likely
never have enough money to buy one. Therefore when buying a cluster you still
have to make compromises.

For example if your user group would benefit from GPU computations, you will
probably want to buy a cluster that will have GPU cards. But since GPU cards
are quite expensive, such cluster will most likely be much smaller than a
cluster without GPU cards.

Now if you have only users with one single orientation, that is just fine. But
if you have heterogenous users, that have different requirements you will soon
run into issues.

And this is the problem that Grids were designed to solve. Grids are an
infrastructural element.  The basic description of a Grid is a set of clusters,
connected using a common infrastructural software to facilitate sharing of
resources.

Now you might sense, that this will be an area with lot of policies and
political issues, and it is. Grid is definitelly about organizations and
infrastructures.

Grid comes with two important notions. The resources providers. Resources
providers are the owners of computing and storage elements that are connected
into the grid.  And virtual organizations. Virtual organizations represent
groups of users, usually with a common interest and negotiate access to
resources with resources providers.

The last model I basically have to talk about is cloud.
Cloud is a slightly strange model, because it isn't a computing model, it is a
business model. Right now, it makes sense to bill access to computing resources
per cpu hour, because the major costs are in the hardware itself and in the
electricity costs.

\section{Metaphor}

So, that should give you an overview of different models you can encounter and
more specifically what is the model we are working with.

Now to actually present you with the issue, allow me a short metaphor.

\subsection{Marketplace}

Imagine a marketplace. On a normal marketplace, customers enter and leave
without any control. The problem with this model is that when a customer enters
a marketplace, he has no guarantee that he will get what he wants.

We have very demanding demanding customers. They don't want to waste their time
entering the market place when their requirements can't be currently met. Some
of our customers don't even want to wait, they just want to hand in a list of
requirements and have their shopping sent to them.

\subsubsection{Mapping}

How does this metaphor map to GRID scheduling? Well, the original marketplace
with no control at all is like buying computers and giving users shell access
to these machines.

Now of course, users are greedy and if you use this approach, very soon you
will run into issues of users using the entire capacity of the machines for
themselves.

The other problem you will run into are guarantees of resources. If a computer
program runs out of memory, it will either crash, or end in some other
forcefull manner. Since many users need to run long (even month long)
computations, you really need to provide some sort of guarantee that the
requested amount of memory will be available on the machine through the entire
life time of the computation.

And in the case of GRID, only few users want interactive access to the
machines. Most just want to enter their requirements, provide a script, that
will run their job and wait for an email notifying them about the result.

\subsubsection{Central authority}

So what does the central authority have to provide?

First of all, we really need to force all users to enter only through this
central authority. So while we may allow users shell access to machines, we
definitelly won't allow any computational jobs being run manually on the machines.

The central authority has to provide the guarantees of resources, therefore we
need to do static allocations. This also allows the central authority to have
less current information about the GRID, because the central authority can
easilly track the current state of each machine locally.

Of course, machine failures still have to be monitored.

\subsubsection{Job scheduling}

So, how hard this problem actually is? Well let's start with the simple variant.
You have some jobs, each with some different length.  And to keep it simple, we
want all of these jobs to finish as soon as possible.  

Example of offline job scheduling.

Unfortunatelly for us, the GRID scheduling problem isn't as simple as that.

One of the problematic parts of GRID scheduling is the combinatoric explosion.
In theoretical problems and solutions, the problem is extremely oversimplified.

First, jobs can be very picky about the machine they want to run on.
So for example you could be only able to run job1, job2, and job3 on machine1 or machine2

In our example the jobs had only one dimension, the length.  In actuallity GRID
jobs are 3 or more dimensional. Each job has length, number of CPUs and memory
requirement. Some jobs have GPU requirements, some have license requirements,
some have disk space requirements.

While the number of dimensions will increase the complexity of the algorith, it
will only result in higher computational complexity. This is a big problem, but
actually the smallest.

One of the big issues is non-claivoirance. We don't really know how long the
jobs will be.  We have some upper limit. But a job with a 24 hour limit can
easily end after 15 minutes.

Problem s online characteristikou problemu.

Problem s merenim uspesnosti rozvrhu.

- how hard is this problem
  - job scheduling
  - oraculum
  - non-claivoirance
  - on-line problem

\subsection{Measuring the success}

What do you do when you have an algorithm that can actually provide a schedule.
How do you compare different algorithms?

What is a good schedule. Now from a user perspective, the only measurement is
how fast the computational jobs get computed. Its as simple as that.

From the resource provider perspective, this is a bit more complex. 

\subsection{Big marketplace}

Lets come back to the marketplace metaphor. So you are now aware of the issue
connected with job sheduling on a single grid aka a marketplace.  Now what
happens, when the marketplace gets to big to maintain. The only option is to split it.

Since the bottle-neck is the central entrance point, we basically want to build
new walls and new entrances into the market place.

The good thing is that we are still in control of the entire market place, and
it is us, who set the policies.

\subsection{Another marketplace}

But this model fails, when we introduce another marketplace into the play.

With one market place being split into multiple parts we still got the controll about the policies we enforce.
With another market place with full autonomy, we can only rely on the agreements established between these two market places.

\end{document}
